{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ifJjwRaEm6YF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"outputId":"9dace8d3-c1e8-4bbe-baf2-7854be2032a1","executionInfo":{"status":"ok","timestamp":1544017484153,"user_tz":-330,"elapsed":16659,"user":{"displayName":"abhay ira","photoUrl":"","userId":"16936421234120284275"}}},"cell_type":"code","source":["!pip install PyDrive\n","\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","download = drive.CreateFile({'id': '1NVQj3GqWFC1i6iLFjjKBFo1XbXm4tv2J'})\n","download.GetContentFile('10k.tsv')\n","\n","download = drive.CreateFile({'id': '1hQU8hmAgBTDDzvYJkl5QvWBrJv2mNlko'})\n","download.GetContentFile('2ke.tsv')\n","\n","download = drive.CreateFile({'id': '1Gr7goLc6blrTl_xTlpvkuCsp_vSyZwD7'})\n","download.GetContentFile('glove.6B.50d.txt')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting PyDrive\n","  Downloading https://files.pythonhosted.org/packages/6b/2d/c8e052ba51099faee0bfe71d84f35bb1576e6910483cad46b840a122ca6c/PyDrive-1.3.1-py2-none-any.whl\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python2.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python2.7/dist-packages (from PyDrive) (1.6.7)\n","Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.4)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.2)\n","Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.11.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n","Installing collected packages: PyDrive\n","Successfully installed PyDrive-1.3.1\n"],"name":"stdout"}]},{"metadata":{"id":"_AOYPxRlqPPB","colab_type":"code","colab":{}},"cell_type":"code","source":["upload = drive.CreateFile({'title': 'EvaluationData.ctf'})\n","upload.SetContentFile('EvaluationData.ctf')\n","upload.Upload()\n","\n","upload = drive.CreateFile({'title': 'TrainData.ctf'})\n","upload.SetContentFile('TrainData.ctf')\n","upload.Upload()\n","\n","upload = drive.CreateFile({'title': 'ValidationData.ctf'})\n","upload.SetContentFile('ValidationData.ctf')\n","upload.Upload()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0V4PZ-JsnNgS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"c21098b2-71e0-4bc4-d58d-af4c0c29a3e3","executionInfo":{"status":"ok","timestamp":1544017550049,"user_tz":-330,"elapsed":44039,"user":{"displayName":"abhay ira","photoUrl":"","userId":"16936421234120284275"}}},"cell_type":"code","source":["!pip  install cntk\n","\n","!head -9000 10k.tsv > traindata.tsv\n","!wc -l traindata.tsv\n","!tail -1000 10k.tsv > validationdata.tsv\n","!mv 2ke.tsv eval1_unlabelled.tsv\n","\n","import re\n","\n","#Initialize Global variables \n","GloveEmbeddings = {}\n","max_query_words = 12\n","max_passage_words = 50\n","emb_dim = 50\n","#The following method takes Glove Embedding file and stores all words and their embeddings in a dictionary\n","def loadEmbeddings(embeddingfile):\n","    global GloveEmbeddings,emb_dim\n","\n","    fe = open(embeddingfile,\"r\")\n","    for line in fe:\n","        tokens= line.strip().split()\n","        word = tokens[0]\n","        vec = tokens[1:]\n","        vec = \" \".join(vec)\n","        GloveEmbeddings[word]=vec\n","    #Add Zerovec, this will be useful to pad zeros, it is better to experiment with padding any non-zero constant values also.\n","    GloveEmbeddings[\"zerovec\"] = \"0.0 \"*emb_dim\n","    fe.close()\n","\n","\n","def TextDataToCTF(inputfile,outputfile,isEvaluation):\n","    global GloveEmbeddings,emb_dim,max_query_words,max_passage_words\n","\n","    f = open(inputfile,\"r\")  # Format of the file : query_id \\t query \\t passage \\t label \\t passage_id\n","    fw = open(outputfile,\"w\")\n","    for line in f:\n","        tokens = line.strip().lower().split(\"\\t\")\n","        query_id,query,passage,label = tokens[0],tokens[1],tokens[2],tokens[3]\n","\n","        #****Query Processing****\n","        words = re.split('\\W+', query)\n","        words = [x for x in words if x] # to remove empty words \n","        word_count = len(words)\n","        remaining = max_query_words - word_count  \n","        if(remaining>0):\n","            words += [\"zerovec\"]*remaining # Pad zero vecs if the word count is less than max_query_words\n","        words = words[:max_query_words] # trim extra words\n","        #create Query Feature vector \n","        query_feature_vector = \"\"\n","        for word in words:\n","            if(word in GloveEmbeddings):\n","                query_feature_vector += GloveEmbeddings[word]+\" \"\n","            else:\n","                query_feature_vector += GloveEmbeddings[\"zerovec\"]+\" \"  #Add zerovec for OOV terms\n","        query_feature_vector = query_feature_vector.strip() \n","\n","        #***** Passage Processing **********\n","        words = re.split('\\W+', passage)\n","        words = [x for x in words if x] # to remove empty words \n","        word_count = len(words)\n","        remaining = max_passage_words - word_count  \n","        if(remaining>0):\n","            words += [\"zerovec\"]*remaining # Pad zero vecs if the word count is less than max_passage_words\n","        words = words[:max_passage_words] # trim extra words\n","        #create Passage Feature vector \n","        passage_feature_vector = \"\"\n","        for word in words:\n","            if(word in GloveEmbeddings):\n","                passage_feature_vector += GloveEmbeddings[word]+\" \"\n","            else:\n","                passage_feature_vector += GloveEmbeddings[\"zerovec\"]+\" \"  #Add zerovec for OOV terms\n","        passage_feature_vector = passage_feature_vector.strip() \n","\n","        #convert label\n","        label_str = \" 1 0 \" if label==\"0\" else \" 0 1 \" \n","\n","        if(not isEvaluation):\n","            fw.write(\"|qfeatures \"+query_feature_vector+\" |pfeatures \"+passage_feature_vector+\" |labels \"+label_str+\"\\n\")\n","        else:\n","            fw.write(\"|qfeatures \"+query_feature_vector+\" |pfeatures \"+passage_feature_vector+\"|qid \"+str(query_id)+\"\\n\")\n","\n","trainFileName = \"traindata.tsv\"\n","validationFileName = \"validationdata.tsv\"\n","EvaluationFileName = \"eval1_unlabelled.tsv\"\n","\n","embeddingFileName = \"glove.6B.50d.txt\"\n","\n","loadEmbeddings(embeddingFileName)    \n","\n","# Convert Query,Passage Text Data to CNTK Text Format(CTF) using 50-Dimension Glove word embeddings \n","TextDataToCTF(trainFileName,\"TrainData.ctf\",False)\n","print(\"Train Data conversion is done\")\n","TextDataToCTF(validationFileName,\"ValidationData.ctf\",False)\n","print(\"Validation Data conversion is done\")\n","TextDataToCTF(EvaluationFileName,\"EvaluationData.ctf\",True)\n","print(\"Evaluation Data conversion is done\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting cntk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/26/f4b6ed23df63ff64b5921b02125f6d0ee4ea92262ee146bce56ed6b449f9/cntk-2.6-cp27-cp27mu-manylinux1_x86_64.whl (74.8MB)\n","\u001b[K    100% |████████████████████████████████| 74.8MB 304kB/s \n","\u001b[?25hRequirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from cntk) (1.1.6)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python2.7/dist-packages (from cntk) (1.14.6)\n","Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python2.7/dist-packages (from cntk) (1.1.0)\n","Installing collected packages: cntk\n","Successfully installed cntk-2.6\n","9000 traindata.tsv\n","Train Data conversion is done\n","Validation Data conversion is done\n","Evaluation Data conversion is done\n"],"name":"stdout"}]},{"metadata":{"id":"2uz69AJ2naVu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":486},"outputId":"7e6c1e3a-2970-43e4-db38-a4156ae13117","executionInfo":{"status":"error","timestamp":1544018220779,"user_tz":-330,"elapsed":935,"user":{"displayName":"abhay ira","photoUrl":"","userId":"16936421234120284275"}}},"cell_type":"code","source":["from __future__ import print_function\n","import numpy as np\n","import sys\n","import os\n","import cntk as C\n","from cntk.io import MinibatchSource, CTFDeserializer, StreamDef, StreamDefs, INFINITELY_REPEAT, FULL_DATA_SWEEP\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.exceptions import UndefinedMetricWarning\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning) "],"execution_count":12,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-12-2403559ab92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcntk\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcntk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinibatchSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCTFDeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStreamDef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStreamDefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINFINITELY_REPEAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFULL_DATA_SWEEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/cntk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Test minimum requirements before running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcntk_py_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mcntk_py_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcntk_check_distro_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcntk_py_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcntk_check_libs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name cntk_py_init","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"J868hMYVne5A","colab_type":"code","colab":{}},"cell_type":"code","source":["!export LD_LIBRARY_PATH=/usr/local/lib"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-XUxACQ_sL9A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f35a373c-63b6-4a86-86d3-08f445e20101","executionInfo":{"status":"ok","timestamp":1544018799027,"user_tz":-330,"elapsed":8319,"user":{"displayName":"abhay ira","photoUrl":"","userId":"16936421234120284275"}}},"cell_type":"code","source":["!python -c \"import sys; print(sys.path)\""],"execution_count":22,"outputs":[{"output_type":"stream","text":["['', '/env/python', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages']\n"],"name":"stdout"}]},{"metadata":{"id":"ZtbDLPT7sMYm","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}